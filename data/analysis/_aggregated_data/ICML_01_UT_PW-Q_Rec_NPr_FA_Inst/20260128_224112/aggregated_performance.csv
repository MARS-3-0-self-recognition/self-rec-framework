evaluator,wikisum/training_set_1-20+test_set_1-30,sharegpt/english_26+english2_74,pku_saferlhf/mismatch_1-20+test_mismatch_1-20+test-mismatch_10_100-200,bigcodebench/instruct_1-50
gpt-4o-mini,0.4396628216503992,0.5013043478260869,0.4786956521739131,0.4930434782608696
gpt-4.1-mini,0.766637089618456,0.5065217391304347,0.4082608695652174,0.491304347826087
gpt-4o,0.45829636202307,0.5185543734865398,0.5830094466936572,0.4834782608695652
gpt-4.1,0.59094942324756,0.5617391304347826,0.5973913043478261,0.6582608695652175
haiku-3.5,0.497338065661047,0.3495652173913043,0.3608695652173913,0.5526086956521739
sonnet-3.7,0.5222646743301197,0.508657125989677,0.6347826086956523,0.6330434782608696
sonnet-4.5,0.7914742905268225,0.5936956521739131,0.7034782608695652,0.6799999999999999
opus-4.1,0.8992826312544178,0.8172636880839291,0.8247826086956521,0.8338410726609484
gemini-2.0-flash-lite,0.2630878438331854,0.5991304347826086,0.1717391304347826,0.4713043478260869
gemini-2.0-flash,0.2928127772848269,0.7405360333531865,0.5069565217391304,0.5808695652173913
ll-3.1-8b,0.4028393966282165,0.4393478260869565,0.1239130434782608,0.488695652173913
ll-3.1-70b,0.4556344276841171,0.4895652173913043,0.5178260869565218,0.4821739130434782
ll-3.1-405b,0.4290150842945874,0.4545413936867183,0.4930434782608696,0.5413768115942029
qwen-2.5-7b,0.4880212954747115,0.4926086956521738,0.5786956521739129,0.4656521739130434
qwen-2.5-72b,0.5146406388642413,0.511304347826087,0.592608695652174,0.5273913043478261
qwen-3.0-80b,0.9685004436557232,0.7919565217391302,0.8608695652173912,0.7330434782608696
deepseek-3.1,0.481810115350488,0.6821739130434782,0.5860869565217391,0.5165217391304348
kimi-k2,0.6273291925465838,0.6668320371626912,0.7143701226309922,0.4908695652173913
